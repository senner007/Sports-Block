{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import OrderedDict\n",
    "def get_sports():\n",
    "    df_sport_latest = pd.read_csv('sports_articles.csv', encoding = \"ISO-8859-1\")\n",
    "    df_sport_2020 = pd.read_csv('sports_articles_2020.csv', encoding = \"ISO-8859-1\")\n",
    "    df_sport_2022 = pd.read_csv('sports_articles_2022.csv', encoding = \"ISO-8859-1\")\n",
    "    df = pd.concat([df_sport_latest, df_sport_2020, df_sport_2022])\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_2_pdset(columns, df):\n",
    "    df_vocab_select_columns = df.iloc[:, columns]\n",
    "    vocab_all_values = df_vocab_select_columns.values.ravel()\n",
    "    return set(vocab_all_values)\n",
    "\n",
    "def vocab_2_dict(sets):\n",
    "    assert(len(sets) == 4)\n",
    "    word_set = sets[0].union(sets[1],sets[2], sets[3])\n",
    "    df = pd.DataFrame(list(word_set), columns=[\"Words\"])\n",
    "    df.sort_values(by=\"Words\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return OrderedDict.fromkeys(word_set)\n",
    "\n",
    "def get_vocab_dict():\n",
    "    df_ods_vocab = pd.read_table('ods_fullforms_2020-08-26.csv', header=None)\n",
    "    df_ddo_vocab = pd.read_table('ddo_fullforms_2020-08-26.csv', header=None)\n",
    "    df_vocab = pd.read_table('cor1.02.tsv', header=None)\n",
    "    df_sport_lingo = pd.read_table('sport_lingo.csv', header=None)\n",
    "\n",
    "    vocab_set = vocab_2_pdset([1,3], df_vocab)\n",
    "    ods_vocab_set = vocab_2_pdset([0,1], df_ods_vocab)\n",
    "    ddo_vocab_set = vocab_2_pdset([0,1], df_ddo_vocab)\n",
    "    sport_lingo_set = vocab_2_pdset([0], df_sport_lingo)\n",
    "\n",
    "    return vocab_2_dict([vocab_set, ods_vocab_set, ddo_vocab_set, sport_lingo_set])\n",
    "\n",
    "ordered_dict = get_vocab_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2408,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sport = get_sports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# isin_dict = False\n",
    "def test_lookup_performance():\n",
    "    word_to_check = \"linebreak\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    for x in range(1000000):\n",
    "        isin_dict = word_to_check in ordered_dict\n",
    "\n",
    "    end_time = time.time()  \n",
    "    assert(end_time - start_time < 1)\n",
    "    print(isin_dict)\n",
    "\n",
    "test_lookup_performance()\n",
    "\n",
    "# isin_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique words: 3019\n",
      "total sports lingo words: 658\n",
      "total vocab: 2361\n",
      "total articles: 363\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "df_sport_text = df_sport.iloc[:, [0,1,2]]\n",
    "\n",
    "train_text = df_sport_text.apply(' '.join, axis=1).to_numpy()\n",
    "\n",
    "words_arr = []\n",
    "\n",
    "def replace_digits(word):\n",
    "    return re.sub(r'\\d+', 'X', word)\n",
    "\n",
    "def remove_specials(word):\n",
    "    characters_to_remove = [':', \"'\", '?', \",\", \".\"]\n",
    "    new_word = word\n",
    "\n",
    "    for char in characters_to_remove:\n",
    "        new_word = new_word.replace(char, '')\n",
    "    return new_word\n",
    "\n",
    "def contains_non_alphanumeric(word):\n",
    "    return bool(re.search(r'[^a-zæøåA-ZÆØÅ0-9]', word))\n",
    "\n",
    "def formatWord(word):\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return replace_digits(word)\n",
    "    \n",
    "    \n",
    "for sentences in range(len(train_text)):\n",
    "    # print(sport_vocab[sentences])\n",
    "    sentence = train_text[sentences].strip()\n",
    "    words = sentence.split()\n",
    "    for word in range(len(words)):\n",
    "        w = words[word]\n",
    "        if contains_non_alphanumeric(w):\n",
    "            w = remove_specials(w)\n",
    "        words_arr.append(w.lower())\n",
    "\n",
    "words_sport_unique = set(words_arr)\n",
    "words_sport_unique_list = list(words_sport_unique)\n",
    "words_sport_lingo = []\n",
    "words_train_vocab = []\n",
    "\n",
    "# TODO : brug tensorflow Tokenezier til at omdanne ord til tokens\n",
    "# TODO : søg i alle leksikoner, søg med og uden bindestreg\n",
    "# TODO : håndter tal ikke i ordbøger eks ( x-x eller x-årig)\n",
    "\n",
    "for w in range(len(words_sport_unique_list)):\n",
    "    word = words_sport_unique_list[w]\n",
    "    if any(char.isdigit() for char in word):\n",
    "        words_train_vocab.append(word)\n",
    "    else: \n",
    "        isin_dict = word in ordered_dict\n",
    "        if (word == \"linebreak\"):\n",
    "            print(\"found\")\n",
    "        if (isin_dict == False):\n",
    "            words_sport_lingo.append(word)\n",
    "        else:\n",
    "            words_train_vocab.append(word)\n",
    "\n",
    "print(\"total unique words:\", len(words_sport_unique) )\n",
    "print(\"total sports lingo words:\", len(words_sport_lingo) )\n",
    "print(\"total vocab:\", len(words_train_vocab))\n",
    "print(\"total articles:\", len(df_sport) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2411,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_sport_lingo\n",
    "file = open('sport_lingo.txt','w')\n",
    "for item in words_sport_lingo:\n",
    "\tfile.write(item+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "\n",
    "file = open('sport_vocab.txt','w')\n",
    "for item in words_train_vocab:\n",
    "\tfile.write(item+\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_2_bool(x):\n",
    "    if type(x) == bool:\n",
    "        return x\n",
    "    assert(type(x) == str)\n",
    "    x_copy = x\n",
    "    x_copy = x_copy.strip()\n",
    "    x_copy = x_copy.lower()\n",
    "    assert(x_copy == \"true\" or x_copy == \"false\")\n",
    "    if x_copy == \"true\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_sport_labels = df_sport['isResult'].apply(lambda x: format_2_bool(x))\n",
    "\n",
    "results_true = df_sport_labels.loc[df_sport_labels== True]\n",
    "results_false = df_sport_labels.loc[df_sport_labels == False]\n",
    "\n",
    "assert(len(results_true) + len(results_false) == len(df_sport_labels))\n",
    "\n",
    "print(len(results_true))\n",
    "print(len(results_false))\n",
    "labels = df_sport_labels.to_numpy().astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n",
      "363\n",
      "(363,)\n",
      "(363,)\n",
      "longest text:  312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"BASKETBALL  Amerikansk basketstjerne tilbageholdt i Rusland:\\xa0'Vi ønsker ikke, at hun bliver en brik i den politiske kamp'  Den amerikanske basketstjerne Brittney Griner har været tilbageholdt i Rusland, siden hun blev stoppet i en lufthavn med cannabisolie i bagagen \""
      ]
     },
     "execution_count": 2414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_sport_text = df_sport.iloc[:, [0,1,2]]\n",
    "\n",
    "\n",
    "# df_sport_text\n",
    "# df_sport_text_combined = df_sport_text.apply(' '.join, axis=1)\n",
    "# train_text = df_sport_text.apply(' linebreak '.join, axis=1).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "print(len(labels))\n",
    "print(len(train_text))\n",
    "print(labels.shape)\n",
    "print(train_text.shape)\n",
    "longest_text = len(max(train_text, key=len))\n",
    "print(\"longest text: \", longest_text)\n",
    "train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['basketball', 'amerikansk', 'basketstjerne', 'tilbageholdt', 'i',\n",
       "       '[UNK]', 'ønsker', 'ikke', 'at', 'hun', 'bliver', 'en', 'brik',\n",
       "       'i', 'den', 'politiske', 'kamp', 'den', 'amerikanske',\n",
       "       'basketstjerne', '[UNK]', 'griner', 'har', 'været', 'tilbageholdt',\n",
       "       'i', '[UNK]', 'siden', 'hun', 'blev', 'stoppet', 'i', 'en',\n",
       "       'lufthavn', 'med', 'cannabisolie', 'i', 'bagagen'], dtype='<U13')"
      ]
     },
     "execution_count": 2415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def replace_digits(word):\n",
    "    return tf.strings.regex_replace(word, pattern=r'\\d+', rewrite=r'X')\n",
    "\n",
    "def remove_specials(word):\n",
    "    return tf.strings.regex_replace(word, pattern=r'[:,\\'\\.]', rewrite=r'')\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    replaced_digits = replace_digits(lowercase)\n",
    "    removed_specials = remove_specials(replaced_digits)\n",
    "    return removed_specials\n",
    "\n",
    "\n",
    "# Model constants.\n",
    "max_features = 2300\n",
    "embedding_dim = 96\n",
    "sequence_length = longest_text + 2\n",
    "\n",
    "# Now that we have our custom standardization, we can instantiate our text\n",
    "# vectorization layer. We are using this layer to normalize, split, and map\n",
    "# strings to integers, so we set our 'output_mode' to 'int'.\n",
    "# Note that we're using the default split function,\n",
    "# and the custom standardization defined above.\n",
    "# We also set an explicit maximum sequence length, since the CNNs later in our\n",
    "# model won't support ragged sequences.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "text_ds = vectorize_layer.adapt(words_train_vocab)\n",
    "\n",
    "vect_vocab = vectorize_layer.get_vocabulary()\n",
    "\n",
    "text_vec = vectorize_layer([train_text[0]])\n",
    "\n",
    "def vect_layer_2_text(vect_l):\n",
    "    return np.array([vect_vocab[x] for x in np.trim_zeros(np.squeeze(vect_l.numpy()))])\n",
    "\n",
    "\n",
    "# text = vect_layer_2_text(text_vec)\n",
    "\n",
    "print(len(vect_vocab))\n",
    "vect_layer_2_text(text_vec)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(90, 400), dtype=int64, numpy=\n",
       "array([[1654,  101, 1445, ...,    0,    0,    0],\n",
       "       [1654,    1,   83, ...,    0,    0,    0],\n",
       "       [1654,    1,    1, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [1424,    1,  904, ...,    0,    0,    0],\n",
       "       [1424,    1,  133, ...,    0,    0,    0],\n",
       "       [   1,  903,  281, ...,    0,    0,    0]])>"
      ]
     },
     "execution_count": 2416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_ds = vectorize_layer(train_text)\n",
    "\n",
    "train_data = train_ds[0:330]\n",
    "val_data = train_ds[330:]\n",
    "\n",
    "train_labels = labels[0:330]\n",
    "val_labels = labels[330:]\n",
    "\n",
    "train_ds\n",
    "val\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# A integer input for vocab indices.\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 20, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 20, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "\n",
    "\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "83/83 [==============================] - 1s 12ms/step - loss: 0.6966 - accuracy: 0.5091 - val_loss: 0.6779 - val_accuracy: 0.6970\n",
      "Epoch 2/12\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.5475 - accuracy: 0.7364 - val_loss: 0.3662 - val_accuracy: 0.8182\n",
      "Epoch 3/12\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.1922 - accuracy: 0.9333 - val_loss: 0.4763 - val_accuracy: 0.8182\n",
      "Epoch 4/12\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.3792 - val_accuracy: 0.8788\n",
      "Epoch 5/12\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0175 - accuracy: 0.9970 - val_loss: 0.3376 - val_accuracy: 0.9091\n",
      "Epoch 6/12\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0290 - accuracy: 0.9970 - val_loss: 0.3597 - val_accuracy: 0.9091\n",
      "Epoch 7/12\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0215 - accuracy: 0.9970 - val_loss: 0.3761 - val_accuracy: 0.8788\n",
      "Epoch 8/12\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.7189 - val_accuracy: 0.7576\n",
      "Epoch 9/12\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9091\n",
      "Epoch 10/12\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 5.8821e-04 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.8485\n",
      "Epoch 11/12\n",
      "83/83 [==============================] - 1s 8ms/step - loss: 5.1736e-04 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.7879\n",
      "Epoch 12/12\n",
      "83/83 [==============================] - 1s 9ms/step - loss: 1.3052e-04 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.7879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4aa1207c40>"
      ]
     },
     "execution_count": 2418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 12\n",
    "# Fit the model using the train and test datasets.\n",
    "model.fit(train_data, train_labels, epochs=epochs, batch_size=4, validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.601486086845398\n",
      "Test accuracy: 0.7878788113594055\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(val_data, val_labels, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision = 2, suppress = True)\n",
    "predictions = model.predict(val_data)\n",
    "\n",
    "print(len(predictions))\n",
    "# print(\"labels:\")\n",
    "# print(val_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['basketball' 'dansk' 'basketstjerne' 'bryder' '[UNK]' 'til' 'verdens'\n",
      " 'bedste' 'liga' 'og' 'har' 'rigtig' 'gode' 'chancer' 'for' 'succes'\n",
      " '[UNK]' '[UNK]' 'har' 'skrevet' 'under' 'på' 'en' 'kontrakt' 'med'\n",
      " '[UNK]' '[UNK]' 'i' 'den' 'amerikanske' 'liga' '[UNK]']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['kvindelandsholdet' 'forrygende' 'første' 'møde' 'med' 'nations' '[UNK]'\n",
      " 'kunne' 'ikke' 'have' 'drømt' 'om' 'mere' 'X-X-sejren' 'over' '[UNK]'\n",
      " 'var' 'lidt' 'af' 'en' 'forløsning' 'for' 'de' 'danske' 'fodboldkvinder']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['basketball' '[UNK]' 'fik' 'fire' 'minutter' 'i' 'drømmeland' 'og'\n",
      " 'entusiasmen' 'vil' 'ingen' 'ende' 'tage' 'natten' 'til' 'mandag' 'dansk'\n",
      " 'tid' 'blev' 'den' 'danske' 'basketballspiller' '[UNK]' '[UNK]' '[UNK]'\n",
      " 'den' 'første' 'dansker' 'til' 'at' 'komme' 'på' 'banen' 'i' '[UNK]']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['cykling' 'det' 'kan' 'blive' 'et' '[UNK]' '[UNK]' 'tager' 'trøjen' 'i'\n",
      " 'dag' 'lover' 'kommentator' '[UNK]' '[UNK]' 'viste' 'tirsdag' 'at'\n",
      " 'formen' 'er' 'hvor' 'den' 'skal' 'være' 'nu' 'venter' 'en' 'af'\n",
      " 'europas' 'sværeste' 'stigninger' 'på' 'X' 'etape' 'af' '[UNK]']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['basketball' '[UNK]' 'i' '[UNK]' 'koster' 'topscorerens' '[UNK]' 'længe'\n",
      " 'haft' 'college' 'som' 'en' 'lille' 'drøm' '[UNK]' 'lind' '[UNK]' 'vil'\n",
      " 'savne' 'landsholdet' 'men' 'gør' 'det' 'for' 'at' 'blive' 'professionel'\n",
      " 'på' 'sigt']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['ol' 'paris' 'X' '[UNK]' 'løfter' 'pegefingeren' 'efter' 'fransk' '[UNK]'\n",
      " 'under' 'ol' 'forbuddet' 'møder' 'kritik' 'fra' 'blandt' 'andet' '[UNK]'\n",
      " 'og' '[UNK]' 'i' 'danmark']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.91]\n",
      "\n",
      " ['badminton' 'vi' 'er' 'blandt' 'de' 'bedste' 'i' '[UNK]' 'trofæ' 'giver'\n",
      " 'badmintonstjerner' 'tro' 'på' 'ol-succes' 'weekendens' 'sejr' 'i'\n",
      " '[UNK]' 'er' 'endnu' 'et' 'bevis' 'på' 'at' 'herredoublen' 'kim' '[UNK]'\n",
      " 'og' '[UNK]' '[UNK]' '[UNK]' 'er' 'i' 'storform']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [0.01]\n",
      "\n",
      " ['basketball' 'bakken' '[UNK]' 'vinder' 'pokalen' 'for' 'X' 'gang' 'med'\n",
      " 'en' 'suveræn' 'sejr' 'på' 'X-X' 'over' '[UNK]' '[UNK]' 'er' 'bakken'\n",
      " '[UNK]' 'for' 'X' 'gang' 'pokalmester' 'i' 'basketball']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['em' '[UNK]' 'minut' 'for' 'minut' 'god' 'slutspurt' 'sikrer' 'to'\n",
      " 'vigtige' 'point' 'til' 'danmark' 'danmarks' 'håndboldlandshold' 'for'\n",
      " 'kvinder' 'tørner' 'sammen' 'med' '[UNK]' 'i' 'første' 'runde' 'af'\n",
      " 'mellemrunden' 'ved' 'em']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['em' '[UNK]' 'stolt' 'landstræner' 'efter' 'dansk' '[UNK]' 'er' 'meget'\n",
      " 'meget' 'glad' '[UNK]' '[UNK]' 'havde' 'mange' 'rosende' 'ord' 'til'\n",
      " 'overs' 'efter' 'danmarks' 'sejr' 'på' 'X-X' 'over' '[UNK]' 'ved' 'em'\n",
      " 'i' 'håndbold']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['motorsport' 'med' 'psykologhjælp' 'og' 'jernvilje' 'er' 'dansker' 'gået'\n",
      " 'fra' '[UNK]' 'til' 'historisk' 'triumf' 'efter' 'en' 'ellers' 'svær'\n",
      " 'sæson' 'vandt' '[UNK]' '[UNK]' 'fredag' 'aften' 'em' 'i' 'speedway'\n",
      " 'for' 'tredje' 'gang' 'i' 'karrieren' 'som' 'den' 'første' 'dansker'\n",
      " 'nogensinde']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['cykling' '[UNK]' 'væbner' 'drømmer' 'om' '[UNK]' 'i' 'touren' 'og' 'det'\n",
      " 'giver' 'god' 'mening' 'det' 'motiverer' '[UNK]' '[UNK]' 'at' 'køre'\n",
      " 'væddeløb' 'og' 'det' 'er' 'oplagt' 'at' 'udnytte' 'i' 'næste' 'års'\n",
      " 'tour' 'til' 'at' 'presse' 'konkurrenterne' 'yderligere' 'mener' '[UNK]'\n",
      " 'sportens' 'cykelekspert']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['basketball' 'cannabis' 'koster' 'amerikansk' 'stjerne' 'ni' 'år' 'i'\n",
      " '[UNK]' 'brik' 'i' 'det' 'store' 'spil' 'mellem' '[UNK]' 'og' '[UNK]'\n",
      " 'den' 'amerikanske' 'basketballspiller' '[UNK]' 'griner' 'er' 'blevet'\n",
      " 'idømt' 'ni' 'års' 'fængsel' 'for' 'narkosmugling' 'i' '[UNK]']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['basketball' 'X-årige' '[UNK]' 'er' 'ugens' 'bedste' 'i' '[UNK]' '[UNK]'\n",
      " 'nu' 'vil' 'hun' 'det' 'ingen' 'dansker' 'før' 'har' 'formået'\n",
      " 'basketball-spilleren' '[UNK]' '[UNK]' 'er' 'kåret' 'som' 'ugens' '[UNK]'\n",
      " 'i' '[UNK]' 'bedste' '[UNK]']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['basketball' 'hallen' 'gyngede' 'og' 'bjørnen' 'dansede' 'da' 'bakken'\n",
      " '[UNK]' 'spillede' 'sig' 'tættere' 'på' 'europæisk' 'finale' 'bakken'\n",
      " '[UNK]' 'vandt' 'den' 'første' 'af' 'to' 'semifinaler' 'i' '[UNK]'\n",
      " '[UNK]' 'cup' 'med' 'X-X' 'over' '[UNK]' '[UNK]' '[UNK]' 'fra' '[UNK]']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['fodbold' '[UNK]' 'har' 'det' 'fint' 'med' 'at' 'blive' 'pustet' 'i'\n",
      " '[UNK]' 'mangler' 'respekt' 'for' 'de' 'andre' 'målmænd' '[UNK]' '[UNK]'\n",
      " 'har' 'på' 'det' 'seneste' 'fået' 'skærpet' 'konkurrence' 'til'\n",
      " 'målmandsposten' 'på' 'det' 'danske' 'landshold']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['motorsport' 'to' 'danskere' 'i' 'direkte' 'duel' 'om' '[UNK]' 'er'\n",
      " 'ikke' 'nogen' 'drømmeposition' 'to' 'danskere' 'skal' 'ud' 'i' 'en'\n",
      " 'direkte' 'dyst' 'om' 'guldet' 'når' 'em' 'i' 'speedway' 'skal' 'afgøres'\n",
      " 'fredag' 'aften']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['hestesport' 'dansk' 'dressurrytter' 'er' 'ekspert' 'i' 'at' 'tage'\n",
      " 'brugte' 'heste' 'til' 'verdenstoppen' '[UNK]' '[UNK]' '[UNK]' 'har' 'i'\n",
      " 'flere' 'omgange' 'overtaget' 'heste' 'fra' 'tidligere' 'ryttere' 'og'\n",
      " 'præsteret' 'med' 'dem' 'som' 'det' 'er' 'også' 'tilfældet' 'ved' 'em'\n",
      " 'i' 'disse' 'dage']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['[UNK]' 'X' 'minut' 'for' 'minut' '[UNK]' 'taber' 'stort' 'til' '[UNK]'\n",
      " 'danmark' 'møder' '[UNK]' 'i' 'den' 'niende' 'og' 'sidste' 'kamp' 'ved'\n",
      " 'ol' 'følg' 'kampen' 'her']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['sport' 'X-årige' '[UNK]' 'træner' 'side' 'om' 'side' 'med'\n",
      " 'gymnastikkens' 'dronning' 'helt' 'surrealistisk' 'ved' 'vm' 'i'\n",
      " 'idrætsgymnastik' 'træner' '[UNK]' 'lund' '[UNK]' 'tæt' 'på' 'den'\n",
      " 'amerikanske' 'superstjerne' '[UNK]' 'biles']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.51]\n",
      "\n",
      " ['superliga' 'X-årig' '[UNK]' 'vendte' 'topbrag' 'på' 'fem' '[UNK]' 'at'\n",
      " 'beskrive' 'fodboldspilleren' '[UNK]' '[UNK]' 'scorede' 'to' 'mål' 'på'\n",
      " 'fem' 'minutter' 'i' 'afslutningen' 'af' 'søndagens' 'Xf'\n",
      " 'superliga-brag' 'mellem' '[UNK]' '[UNK]' 'og' '[UNK]']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['em' '[UNK]' 'landsholdets' 'trænerduo' 'har' 'uddelt' 'håndmadder' 'men'\n",
      " 'supplerer' 'nu' 'hinanden' 'som' 'pot' 'og' 'pande' 'landstræner'\n",
      " '[UNK]' '[UNK]' 'og' 'hans' 'assistent' '[UNK]' '[UNK]' 'kender'\n",
      " 'hinanden' 'ud' 'og' 'ind']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.04]\n",
      "\n",
      " ['amerikansk' 'fodbold' '[UNK]' 'froholdt' 'slap' 'godt' 'fra' 'debuten'\n",
      " 'i' 'jobbet' 'som' 'der' 'kun' 'findes' 'X' 'af' 'i' 'verden' 'den'\n",
      " 'danske' 'amerikanske' 'fodboldspiller' 'er' 'førstevalg' 'som' 'center'\n",
      " 'i' 'den' 'offensive' 'linje' 'for' '[UNK]' '[UNK]' 'i' '[UNK]']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.09]\n",
      "\n",
      " ['em' '[UNK]' 'danmark' 'må' 'nøjes' 'med' 'em-sølv' 'efter' 'nederlag'\n",
      " 'til' '[UNK]' 'håndboldkvinder' 'danmarks' 'håndboldlandshold' 'taber'\n",
      " 'til' '[UNK]' 'med' 'X-X' 'i' 'em-finalen']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['basketball' 'svensk' 'stjernespiller' 'smidt' 'på' 'porten' 'efter'\n",
      " 'forbudt' 'russisk' '[UNK]' 'forstår' 'ham' 'basketballspilleren' '[UNK]'\n",
      " '[UNK]' 'er' 'blevet' 'suspenderet' 'fra' 'det' 'svenske' 'landshold'\n",
      " 'efter' 'han' 'har' 'underskrevet' 'en' 'kontrakt' 'med' 'den' 'russiske'\n",
      " 'storklub' '[UNK]' '[UNK]' 'en' 'trist' 'dag' 'for' 'sporten' 'siger'\n",
      " 'svensk' 'journalist']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['badminton' '[UNK]' 'fik' 'pludselig' 'privatlektion' 'af' 'amerikansk'\n",
      " '[UNK]' 'er' 'jo' 'en' 'fantastisk' 'atlet' 'den' 'danske'\n",
      " 'badmintonspiller' 'kan' 'lære' 'meget' 'af' 'basketballspillere'\n",
      " 'fortæller' 'han']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.98]\n",
      "\n",
      " ['ol' 'paris' 'X' 'superstjerne' 'klar' 'til' '[UNK]' 'med' 'utrolig'\n",
      " 'svært' 'spring' '[UNK]' 'biles' 'er' 'tilbage' 'på' 'den' 'store'\n",
      " '[UNK]' 'når' 'hun' 'i' 'weekenden' 'deltager' 'ved' 'vm']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.52]\n",
      "\n",
      " ['[UNK]' 'overlegne' '[UNK]' 'håndbold' 'vinder' 'med' 'X' 'mål' 'i'\n",
      " 'champions' 'league' 'de' 'danske' 'håndboldkvinder' 'vandt'\n",
      " 'overbevisende' 'over' '[UNK]' 'fra' '[UNK]' 'i' 'champions' 'league']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n",
      "\n",
      " ['sport' 'efter' 'halvandet' 'års' 'venten' 'kommer' 'der' 'nu' 'endelig'\n",
      " 'en' 'afgørelse' 'i' 'russisk' 'ol-guldvinders' 'dopingsag' 'tirsdag'\n",
      " 'begynder' 'den' 'internationale' 'sportsdomstols' 'høring' 'i' 'sagen'\n",
      " 'om' '[UNK]' '[UNK]']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.02]\n",
      "\n",
      " ['em' '[UNK]' 'hviledagene' 'falder' 'perfekt' 'efter' 'hektisk' '[UNK]'\n",
      " 'er' 'så' 'sindssygt' 'svært' 'efter' 'fem' 'kampe' 'på' 'ni' 'dage'\n",
      " 'kan' 'de' 'danske' 'em-spillere' 'nu' 'se' 'frem' 'til' 'et'\n",
      " 'velfortjent' 'hvil']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.99]\n",
      "\n",
      " ['basketball' 'dansker' 'får' 'spansk' '[UNK]' 'som' '[UNK]' 'af' 'de'\n",
      " 'ting' 'jeg' 'om' 'mange' 'år' 'vil' 'huske' 'tilbage' 'på' 'den'\n",
      " 'danske' 'basketballspiller' 'mads' 'bonde' 'får' 'den' 'spanske'\n",
      " 'verdensstjerne' 'marc' '[UNK]' 'som' 'holdkammerat']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.]\n",
      "\n",
      " ['tennis' 'selvom' 'demonstranter' 'afbrød' 'tennisdarlings'\n",
      " 'historiedefinerende' 'øjeblik' 'var' 'hun' 'ikke' 'sur' '[UNK]'\n",
      " 'open-semifinalen' 'mellem' '[UNK]' '[UNK]' 'og' '[UNK]' '[UNK]' 'blev'\n",
      " 'stoppet' 'i' 'X' 'minutter']\n",
      "-- LABEL --: 0\n",
      "-- Prediction --: [0.95]\n",
      "\n",
      " ['ligetil' '[UNK]' 'vinder' 'vm' 'i' 'basketball' 'søndag' 'vandt' '[UNK]'\n",
      " 'vm' 'i' 'basketball' 'det' 'er' 'anden' 'gang' 'at' '[UNK]' 'bliver'\n",
      " 'verdensmestre' 'i' 'basketball']\n",
      "-- LABEL --: 1\n",
      "-- Prediction --: [1.]\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(val_data)):\n",
    "    print(\"\\n\" ,vect_layer_2_text(val_data[x]))\n",
    "    print(\"-- LABEL --:\" , val_labels[x])\n",
    "    print(\"-- Prediction --:\" , predictions[x])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be0503bf1d8a1ee3ca0077be831d95fbcddd9686f11808f41fa1809452b7e6ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
