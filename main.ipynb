{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import OrderedDict\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data/labels length:  8339 8339\n",
      "Validation data/labels length:  347 347\n"
     ]
    }
   ],
   "source": [
    "from csv_data import get_vocab_dict\n",
    "from csv_data import get_sports\n",
    "from csv_data import csv_to_list\n",
    "from csv_data import split_data\n",
    "from csv_data import extract_data\n",
    "from csv_data import check_duplicates\n",
    "\n",
    "\n",
    "# # TODO : fjern ord der er kategorisert som \"egennavn\" i ddo_fullforms_2020-08-26.csv\n",
    "\n",
    "ordered_dict = get_vocab_dict()\n",
    "df_sport = get_sports()\n",
    "nationalities = csv_to_list('resources/nat2.csv')\n",
    "danske_navne = csv_to_list('resources/danmark_navne.csv')\n",
    "andre_navne = csv_to_list('resources/andre_navne.csv')\n",
    "countries = csv_to_list('resources/countries.csv')\n",
    "navne = csv_to_list('resources/navne.csv')\n",
    "\n",
    "def get_results_in_data(train_data, train_labels):\n",
    "    results = []\n",
    "    for t in range(len(train_data)):\n",
    "        if train_labels[t] == 1:\n",
    "            results.append(train_data[t])\n",
    "    \n",
    "    return results\n",
    "\n",
    "# train_data_results = get_results_in_data(train_data, train_labels)\n",
    "\n",
    "data_total, labels_total = extract_data(df_sport)\n",
    "check_duplicates(data_total)\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = split_data((data_total, labels_total), 4)\n",
    "\n",
    "# print(\"Total data: \", len(train_text))\n",
    "print(\"Train data/labels length: \", len(train_data), len(train_labels))\n",
    "print(\"Validation data/labels length: \", len(val_data),  len(val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORMEL 1 . Derfor vinder Verstappen VM: Magnussen, mekanikeren og chefen om suveræn superstjerne . Max Verstappen er i Singapore favorit til sin 11. sejr i træk, og allerede næste weekend kan han sikre sig VM-titlen\n",
      "0\n",
      "Basketball . NBA-stjerne ramt af knæskade . Den firedobbelte NBA-vinder Stephen Curry har pådraget sig en knæskade, der kan holde ham ude i flere uger\n",
      "0\n",
      "Amerikansk fodbold . - Hvis ikke de vinder, vil det være en kæmpe skuffelse . De sidste pladser i slutspillet og de altafgørende seedninger er på spil i den sidste række af kampe i grundspillet i NFL\n",
      "0\n",
      "SPORT . JP-journalist vinder fornem pris . Jyllands-Postens journalist Dan Philipsen blev onsdag kåret som Årets Sportsjournalist 2009\n",
      "0\n",
      "HERRELANDSHOLDET . Så længe landsholdet vinder, behøver det ikke være en berusende fodboldfest . Det danske landshold ved godt, at de skal vinde, når de møder Finland i en afgørende gruppekamp i EM-kvalifikation\n",
      "0\n",
      "Amerikansk fodbold . Et enigt ekspertpanel udpeger Super Bowl-favorit . TV 2 SPORTs NFL-eksperter peger alle på Philadelphia Eagles som vinder, når der i nat spilles årets udgave af Super Bowl\n",
      "0\n",
      "SPORT . Le Mans-vinderen hyldet i Tivoli . Den syvdobbelte Le Mans-vinder, Tom Kristensen, blev mandag aften hyldet i Tivoli\n",
      "0\n",
      "Tennis . Holger Rune - Dominic Thiem . Hvad skete der? Holger Rune åbnede sit titelforsvar i Paris Masters, da han den tidligere Grand Slam-vinder Dominic Thiem i anden runde\n",
      "0\n",
      "TOUR DE FRANCE . Milliardær troede, han havde gjort et kup, men kritiserer nu Tour-konge . Israel-Premier Techs holdejer retter kritik mod den firedobbelte Tour de France-vinder Chris Froome\n",
      "0\n",
      "GOLF . Golfstjerne beskylder PGA-top for skruppelløs enegang . Den dobbelte The Open-vinder Ernie Els mener, at PGA Tourens top skal ud på grund af samarbejde med LIV Golf\n",
      "0\n",
      "Basketball . Med dette skud vinder 12-årig dreng dyr ring - men han må ikke beholde den . Det er første gang i klubbens historie, at præmien bliver indløst\n",
      "0\n",
      "CYKLING . Vingegaard vil vinde andet end Touren: 'Kan være, jeg skal gøre noget anderledes' . Tour de France-vinderen Jonas Vingegaard skal stadig vænne sig til tanken om at være kaptajn for et af verdens bedste cykelhold\n",
      "0\n",
      "SPORT . Usain Bolt: Jeg vinder VM med lethed . Fartfænomenet er et godt stykke fra sin bedste form. Alligevel er Usain Bolt sikker på sig selv før VM\n",
      "0\n",
      "Håndbold . Ingen dansk klub har nogensinde investeret så meget - de vinder suverænt . Læs håndboldekspert Bent Nyegaards store sæsonoptakt for hvert hold i herreligaen. Han giver også sit bud på deres slutplacering\n",
      "0\n",
      "VM fodbold . Adopterer qatarsk kat, hvis England vinder VM . Der er god stemning i den engelske landsholdslejr, hvor Kyle Walker og John Stones har fået en ny \"kammerat\"\n",
      "0\n",
      "FIFA VM 2022 . Vinder Danmark VM? Modstanderne har stor respekt for det danske 'dræbergen' . Journalister fra Tunesien, Frankrig og Australien forventer alle, at Danmark når langt til VM i Qatar\n",
      "0\n",
      "Tour de France . Vingegaard stjæler overskrifter i udlandet . Flere medier er allerede nu klar til at kåre Jonas Vingegaard som vinder\n",
      "0\n",
      "Formel 1 . Magnussen vinder fornem pris . Kevin Magnussen deler nu pris med blandt andre Valtteri Bottas, Daniel Ricciardo og Lewis Hamilton\n",
      "0\n",
      "OL . Superstjerne dropper finaler på stribe - men alligevel er hun den største vinder . Gymnasten Simone Biles har på nuværende tidspunkt meldt fra til fire discipliner ved OL af mentale årsager\n",
      "0\n",
      "Basketball . Russiske myndigheder tilbageholder amerikansk OL-vinder . Brittney Griner er blevet tilbageholdt for besiddelse af cannabisolie og risikerer op til ti års fængsel\n",
      "0\n",
      "KORT SPORT . Konkurrent letter på hatten og forudser Vingegaard-sejr . Mens Jonas Vingegaard endnu ikke selv er klar til at se hele vejen til Paris, er en af hans hårdeste konkurrenter ikke bange for at udnævne danskeren til vinder af Tour de France\n",
      "0\n",
      "Atletik . Sara Slotts træner modsiger ekspert - tror de vinder protesten . Mikkel Larsen fortæller, at Sara Slott Petersen er knust over diskvalificeringen. Den danske lejr tror dog, at hun er med til semifinalen\n",
      "0\n",
      "KORT SPORT . Svensk atletikstjerne vinder stor pris . Den svenske stangspringer Armand Duplantis vandt mandag aften prisen som årets bedste mandlige atletikudøver i verden\n",
      "0\n",
      "Tennis . Eksperter ser frem til drømmefinale . Eksperter spår, at Djokovics rutine kan gøre, at han vinder sin ottende Wimbledon-titel\n",
      "0\n",
      "Vuelta a España . Vingegaard har klar opfordring til Kuss . Den danske Tour de France-vinder er klar til at miste Sepp Kuss som hjælper\n",
      "0\n",
      "Tennis . Verdens nummer et er klar til brag i semifinalen . Sabalenka skal møde Swiatek i semifinalen. Vinder hun, slutter hun året som nummer et på verdensranglisten\n",
      "0\n",
      "Tennis . Runes farvel til Basel var kedeligt, men Paris står allerede klar med åbne arme . I den franske hovedstad er de vilde med den forsvarende vinder af Paris Masters\n",
      "0\n",
      "Atletik . Verdenseliten raser over ny regel - længste spring vinder ikke længere . Et nyt format kaldet 'Final three' indebærer under Diamond League, at det ikke nødvendigvis er atleten med det længste spring, der vinder\n",
      "0\n",
      "Atletik . Kenyansk maratonstjerne løber ind i dopingkarantæne . Den tidligere vinder af London Marathon Daniel Wanjirus biologiske pas har afsløret ham i brug af doping\n",
      "0\n",
      "OL . Specialist spår Asgreen store chancer for OL-medalje . Som forsvarende DM-vinder i enkeltstart er der store forventninger til Kasper Asgreen, når han skal i kamp mod uret på OL-enkeltstarten\n",
      "0\n",
      "Boksning . Kontrakt underskrevet - dato på plads for årets danske boksebrag . Lolenga Mock bokser til september den største kamp i år i dansk boksning. Vinder han den, får han en VM-kamp\n",
      "0\n",
      "Volleyball . Danmark favorit i volley-kvalen . I første runde af kvalifikationen frem mod EM i volleyball i 2009 skal Danmark møde Storbritannien i en kamp, hvor Danmark nødvendigvis må regnes som svage favoritter, selvom modstanderne for første gang stiller op som samlet nation. Vinder danskerne, byder det på puljespil mod Belgien, Grækenland og vinderen af Østrig-Sverige\n",
      "0\n",
      "KORT SPORT . Anne-Marie Rindoms træner vinder pris . Bag de fleste store sportslige resultater findes en træner, der hjælper med at få præstationerne at gå op i en højere enhed\n",
      "0\n",
      "Vuelta a España . - Det var ikke mit stolteste øjeblik, siger Vingegaard om maveonde . Maveproblemer tvang den danske Tour-vinder af cyklen i første uge af Vuelta a España\n",
      "0\n",
      "Basketball . Ikon roser NBA-dansker . Den tidligere NBA-vinder David Lee giver også danske Gabriel 'Iffe' Lundberg lidt gode råd med på vejen\n",
      "0\n",
      "Håndbold . Danmark er klar, klar favorit ifølge Nyegaard . Den kommende EM-slutrunde spilles i Tyskland fra 10. til 28. januar 2024. Sverige er forsvarende vinder\n",
      "0\n",
      "Tennis . - Umuligt at komme tilbage, siger ekspert om dopingdømte Halep . Den dobbelte Grand Slam-vinder står til fire års karantæne fra tennissporten efter brud på dopingregler\n",
      "0\n",
      "TOUR DE FRANCE . Er du enig i DR-kommentators gule barometer? Stem på Vingegaards vinderchancer her . Inden hver etape vurderer DR Sportens cykelkommentator Tobias Hansen chancen for at Jonas Vingegaard genvinder Tour de France . Prøv selv kræfter med Det Gule Barometer her\n",
      "0\n",
      "SUPERLIGA . Jonas Dal før mødet med Hobro: Esbjerg - vi vinder . Jonas Dal står i sin blot fjerde kamp som træner for Esbjerg på søndag over for sin tidligere klub Hobro\n",
      "0\n",
      "Volleyball . Team Danmark vinder sag mod forbund . Team Danmark kan ånde lettet op, efter Østre Landsret torsdag afsagde dom i en principiel sag rejst af Dansk Volleyball Forbund om støttekroner, der kunne have kostet eliteorganisationen et større millionbeløb\n",
      "0\n",
      "SPORT . Kessler: Jeg vinder VM-bæltet i Parken . Mikkel Kessler er sikker på, at han slår den tyske verdensmester Robert Stieglitz på hjemmebane i København\n",
      "0\n",
      "ISHOCKEY . Lars Eller: Stanley Cup-trofæ skal få unge til at drømme . Den danske NHL-vinderer har i denne uge trofæet med hjem til Danmark. Han opfordrer de unge til at tænke stort\n",
      "0\n",
      "CYKLING . 'Kunne aldrig gøre det uden dem': På Vingegaards tidligere hold lærer man, at hvert løb skal køres som et VM . Jonas Vingegaard er én af mange danske talenter, som har taget springet fra Danmark til udlandet. Kom med Tour de France-vinderens tidligere hold til løbsdag i Gesten lidt vest for Kolding\n",
      "0\n",
      "Golf . Helligkilde vinder Den Gyldne Golfbold . Golfspilleren Marcus Helligkilde vinder prisen Den Gyldne Golfbold for sine præstationer på Challenge Tour\n",
      "0\n",
      "Tennis . Wimbledon-mester venter Wozniacki - og det bliver en udfordring for begge . Caroline Wozniacki ligner ikke en, der har været væk i 3,5 år, mener Wimbledon-vinderen Marketa Vondrousova\n",
      "0\n",
      "Ishockey . Lars Eller skifter til regerende Stanley Cup-vinder . Efter syv år hos Washington Capitals fortsætter Lars Eller karrieren hos Colorado Avalanche\n",
      "0\n",
      "KORT SPORT . Årets hold: Dansk baskettalent vinder endnu en pris i USA . Alberte Rimdal har været rigtig god med en basketball i år\n",
      "0\n",
      "Badminton . Vinderinterview med dansk double måtte afbrydes . Det var svært at holde tårerne tilbage\n",
      "0\n",
      "KORT SPORT . Tidligere Tour de France-vinder forlænger med Ineos . 37-årige Geraint Thomas har forlænget sin kontrakt med cykelholdet Ineos Grenadiers\n",
      "0\n",
      "Skydning . Skidronning er udskrevet fra hospitalet . Det amerikanske skifænomen Lindsey Vonn er onsdag udskrevet fra det hospital i Colorado, hvor den firedobbelte World Cup-vinder de seneste to dage er blevet behandlet for kraftige smerter i tarmen\n",
      "0\n",
      "Ishockey . Ellers stjernekollega er \"nok mest skuffet af alle\" . Lars Ellers holdkammerat Alexander Ovechkin misser muligheden for at blive vinder af VM, NHL og OL\n",
      "0\n",
      "Fodbold . Lionel Messi vinder Ballon d'Or for ottende gang . Det argentinske boldgeni Lionel Messi er igen kåret som verdens bedste fodboldspiller. Aitana Bonmatí vandt hos kvinderne\n",
      "0\n",
      "Tour de France . Vingegaards forældre tror, Pogacar vinder . Etapens hårdhed passer Tadej Pogacar bedre, mener Karina og Claus\n",
      "0\n",
      "Badminton . Astrup joker med Skaarup: - Én dårlig ting ved at være i VM-finalen . Der var plads til vittigheder i vinderinterviewet\n",
      "0\n",
      "Amerikansk fodbold . Tidligere Super Bowl-vinder undskylder for at banke mand med flaske . McGinest er blandt de bedste spillere i New England Patriots' historie. Linebacken spillede 11 år i klubben og vandt Super Bowl tre gange\n",
      "0\n",
      "Håndbold . Vipers venter for Team Esbjerg i en potentiel Champions League-finale . Hvis Team Esbjerg vinder sin CL-semifinale, venter de forsvarende mestre fra Vipers i søndagens finale\n",
      "0\n",
      "Golf . British Open-vinder skifter til omstridt golftour . Verdenstoeren Cameron Smith dropper PGA Touren for i stedet at spille den omstridte turneringsserie LIV Golf\n",
      "0\n",
      "CYKLING . Jonas Vingegaard prioriterer sit hold over sit land . Tour de France-vinderen vil fokusere på Jumbo-Visma og fravælger derfor at prioritere VM, siger landstræner\n",
      "0\n",
      "Amerikansk fodbold . Tidligere Super Bowl-vinder Demaryius Thomas er død . Politiet har fundet Demaryius Thomas i hans hjem, og han er formentlig død af helbredsmæssige årsager\n",
      "0\n",
      "Sejlsport . Windsurfing i Klitmøller aflyst på grund af manglende vind . Vinden blev væk under World Cuppen i Klitmøller, hvilket gjorde det umuligt at kåre en vinder\n",
      "0\n",
      "BASKETBALL . Dansk sportsdirektør har vænnet sig til voldsom sejrsstime . Bakken Bears kan vinde sit 20. mesterskab, hvis basketball klubben vinder over Svendborg Rabbits i DM-finalerne\n",
      "0\n",
      "SEJLSPORT . Efter tre måneders tænkepause: Dansk OL-guldvinder tager endnu en tørn i vinderbåden - men meget bliver anderledes . Anne-Marie Rindoms næste store mål er OL i 2024, men forberedelserne bliver anderledes\n",
      "0\n",
      "SPORT . Mexicos første kvindelige OL-vinder dør som 36-årig . Den kvindelige vægtløfter Soraya Jimenez er død efter et hjerteanfald. Hun vandt OL-guld i 2000\n",
      "0\n",
      "Vuelta a España . Dét sagde Kuss, inden Vingegaard og Roglic satte ham . Selvom Vingegaard ikke ventede på Kuss, håber han stadig, at amerikaneren vinder løbet samlet\n",
      "0\n",
      "TYSK FODBOLD . Ribery føler sig sikker: Jeg vinder Ballon d'Or . Franskmanden mener, han er verdens bedste fodboldspiller. Ronaldo er ikke en trussel\n",
      "0\n",
      "Cykling . En dum beslutning af Roglic, mener ekspert . Årets Giro d'Italia-vinder siger farvel til Jumbo-Visma efter otte års ægteskab\n",
      "0\n",
      "Tour de France . Rørt etapevinder føler, han forrådte Asgreen . Matej Mohoric var i tårer i sit vinderinterview\n",
      "0\n",
      "Tour de France . Farvel til Glyngøre? Vingegaard og familien har flytteplaner . Den dobbelte Tour-vinder Jonas Vingegaard og familien overvejer at flytte fra Danmark\n",
      "0\n",
      "BASKETBALL . 99 ud af 100 gange bliver aarhusianerne danske mestre, men 'der er sprækker i dominansen' . Sølv er noget, du vinder, hvis du ikke hedder Bakken Bears, siger Horsens IC og Svenborg Rabbits. De to baskethold mødes i aften i DM-semifinalen\n",
      "0\n",
      "Tennis . Rune spiller som en vinder af turneringen, siger ekspert . Ekspert Michael Tauson ser en Holger Rune, der storspiller i Basel, men som stadig kan blive bedre\n",
      "0\n",
      "Fodbold . Eksperterne er ikke et sekund i tvivl om, hvem der vinder Ballon d'Or . Messi har syv gange vundet den fornemme pris. Det har ingen anden præsteret\n",
      "0\n",
      "Basketball . Traditionsklub vinder lotteriet - fransk vidunderbarn på vej . Natten til onsdag blev der trukket lod om, hvem der får lov til at vælge først, når NBA-draften løber af stablen\n",
      "0\n",
      "VM fodbold . Selv Argentinas største rivaler håber, at Messi vinder VM-guld . Flere legender holder med Lionel Messi under søndagens VM-finale\n",
      "0\n",
      "Tour de France . Udlandet: Robotten Vingegaard stak kniven ind . Den danske Tour de France-vinder fylder hos udenlandske medier\n",
      "0\n",
      "KORT SPORT . Fodboldlandsholdet vinder fair play-pris . Herrelandsholdet i fodbold modtager prisen Special World Fair Play Trophy, som bliver uddelt af Den Internationale Fair Play Komité\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for i,tt in enumerate(data_total):\n",
    "    if re.search(r'\\bvinder', tt, re.IGNORECASE):\n",
    "        if (labels_total[i] == 0):\n",
    "            print(tt)\n",
    "            print(labels_total[i])\n",
    "        # print(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4692 3647]\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_labels)\n",
    "# print(\n",
    "#     \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "#         counts[1], 100 * float(counts[1]) / len(train_labels)\n",
    "#     )\n",
    "# )\n",
    "\n",
    "print(counts)\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_articles_to_csv():\n",
    "    df_sport_combined = df_sport.copy().drop('Link', axis=1)\n",
    "    df_sport_combined.to_csv('articles_temp/combined.csv')\n",
    "\n",
    "combine_articles_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in data points: \n",
      "Empty DataFrame\n",
      "Columns: [Category, Headline, SubHeading, Link, isResult, isMaybe]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = df_sport.duplicated()\n",
    "print(\"Duplicates in data points: \")\n",
    "print(df_sport[duplicate_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "isin_dict = False\n",
    "def test_lookup_performance():\n",
    "    word_to_check = \"Dansk\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    for x in range(1000000):\n",
    "        isin_dict = word_to_check in ordered_dict\n",
    "\n",
    "    end_time = time.time()  \n",
    "    assert(end_time - start_time < 1)\n",
    "    print(isin_dict)\n",
    "\n",
    "test_lookup_performance()\n",
    "\n",
    "# isin_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['o', 'real', 'mads', 'norman', 'trine', 'rune', 'groves', 'tiger', 'kim', 'søren', 'mark', 'signe']\n",
      "total unique words: 9176\n",
      "total sports lingo words: 2203\n",
      "total vocab: 6973\n",
      "total articles: 8686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# train_text = df_sport.iloc[:, [0,1,2]].apply(' . '.join, axis=1).replace('\\xa0', '', regex=True).to_numpy()\n",
    "# train_text_results = df_sport.loc[df_sport['isResult'] == True].iloc[:, [0,1,2]].apply(' . '.join, axis=1).replace('\\xa0', '', regex=True).to_numpy()\n",
    "\n",
    "from create_vocab import split_sentences\n",
    "from create_vocab import remove_duplicates\n",
    "from create_vocab import remove_nationalities\n",
    "from create_vocab import remove_danske_navne\n",
    "from create_vocab import remove_danske_fornavne\n",
    "from create_vocab import remove_numeric\n",
    "from create_vocab import remove_non_dict_words\n",
    "from create_vocab import add_non_alpha_numeric\n",
    "\n",
    "# words_total =  train_data.copy()\n",
    "# words_total.extend(val_data)\n",
    "\n",
    "def words_by_frequency(arr):\n",
    "    xx = np.array(arr, dtype=object)\n",
    "    unique, counts = np.unique(xx, return_counts=True)\n",
    "    aa = np.asarray((unique, counts)).T\n",
    "    return np.flip(aa[aa[:, 1].argsort()])\n",
    "\n",
    "def remove_non_frequent(words_arr, threshold):\n",
    "    words_dict = words_by_frequency(words_arr)\n",
    "    words_above_threshold = []\n",
    "    for f in words_dict:\n",
    "        if f[0] > threshold:\n",
    "            words_above_threshold.append(f[1])\n",
    "    return words_above_threshold\n",
    "\n",
    "\n",
    "sentence_words = split_sentences(train_data)\n",
    "sentence_words_frequent = remove_non_frequent(sentence_words, 1)\n",
    "words_arr_unique = remove_duplicates(sentence_words_frequent)\n",
    "words_arr_unique = remove_nationalities(words_arr_unique, nationalities)\n",
    "words_arr_unique = remove_danske_navne(words_arr_unique, danske_navne)\n",
    "words_arr_unique = remove_danske_fornavne(words_arr_unique, andre_navne)\n",
    "words_arr_unique = remove_numeric(words_arr_unique)\n",
    "\n",
    "words_train_vocab, words_sport_lingo = remove_non_dict_words(words_arr_unique, ordered_dict)\n",
    "\n",
    "\n",
    "\n",
    "# # TODO : brug tensorflow Tokenezier til at omdanne ord til tokens\n",
    "# # TODO : søg i alle leksikoner, søg med og uden bindestreg\n",
    "# # TODO : håndter tal ikke i ordbøger eks ( x-x eller x-årig)\n",
    "# # TODO : lemmatizer : udelad bøjninger af samme navneord. eks : verdensmester/verdensmesteren\n",
    "# # TODO : evt. grupper ord der ofte hænger sammen med nltk BigramFinder. eks vandt over\n",
    "# TODO : fjern evt. også alle navne (fornavne og efternavne)  \n",
    "\n",
    "print(\"total unique words:\", len(words_arr_unique) )\n",
    "print(\"total sports lingo words:\", len(words_sport_lingo) )\n",
    "print(\"total vocab:\", len(words_train_vocab))\n",
    "print(\"total articles:\", len(df_sport) )\n",
    "\n",
    "# for d in df_sport['isResult']:\n",
    "#     if isinstance(d, bool) != True:\n",
    "#         print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6973"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(words_train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('words_sport_lingo.txt','w')\n",
    "for item in words_sport_lingo:\n",
    "\tfile.write(item+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "file = open('words_train_vocab.txt','w')\n",
    "for item in sorted(words_train_vocab):\n",
    "\tfile.write(item+\"\\n\")\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wahl\n",
      "grimmel\n",
      "maulana\n",
      "arnesen\n",
      "spejlsgaard\n",
      "psv\n",
      "eto\n",
      "torben\n",
      "dominic\n",
      "sico\n",
      "rathore\n",
      "schip\n",
      "eindhoven\n",
      "thuesen\n",
      "værtsbud\n",
      "altmaier\n",
      "asbjørn\n",
      "emmons\n",
      "mowinckel\n",
      "thiem\n",
      "svensson\n",
      "corporation\n",
      "ragnhild\n",
      "skeet\n",
      "diaz\n",
      "goldings\n",
      "kazan\n",
      "meyerhoff\n",
      "carlisle\n",
      "golding\n",
      "tite\n",
      "grundsøe\n",
      "lahoz\n",
      "mateu\n",
      "goncalo\n",
      "klaveness\n",
      "fikri\n",
      "ke\n",
      "nairo\n",
      "samuel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# TODO : lav en negativ liste også\n",
    "# display most frequent words found in lingo words\n",
    "for f in remove_duplicates(sentence_words):\n",
    "    if f in words_sport_lingo and f not in navne and len(f) > 1:\n",
    "        print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO : lav en negativ liste også\n",
    "# display most frequent words found in lingo words\n",
    "# words_that_appear_once = []\n",
    "# for f in frequent_words:\n",
    "#     if f[0] < 2 and f[1] not in navne:\n",
    "#         words_that_appear_once.append(f[1])\n",
    "\n",
    "# # print(len(words_that_appear_once))\n",
    "# sorted(words_that_appear_once)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# f = frequent_words[-300:]\n",
    "# ff = []\n",
    "# for w in frequent_words:\n",
    "#     if w[1] in words_train_vocab and w[0] < 2:\n",
    "#         ff.append(w[1])\n",
    "\n",
    "# print(len(ff))\n",
    "# ff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocab/max_features :  6917\n",
      "['tidligere' 'formel' 'xnumber' 'kører' 'vinder' '[UNK]' 'guld' 'den'\n",
      " 'tidligere' 'formel' 'xnumber' 'kører' '[UNK]' '[UNK]' 'kørte' 'galt' 'i'\n",
      " 'xyear' 'og' 'mistede' 'begge' 'sine' 'ben' '.' 'i' 'dag' 'vandt' 'han'\n",
      " 'guld' 'ved' '[UNK]' 'i' 'håndcykel' '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from vectorization import replace_finals, replace_nationality, to_lower\n",
    "from vectorization import split_dash\n",
    "from vectorization import split_included_specials\n",
    "from vectorization import replace_tournament\n",
    "from vectorization import replace_countries\n",
    "from vectorization import replace_weekday\n",
    "from vectorization import replace_digits\n",
    "from vectorization import vect_layer_2_text\n",
    "from vectorization import vectorize_layer\n",
    "from vectorization import standardize\n",
    "from static_data import tournaments\n",
    "from static_data import weekdays\n",
    "from static_data import non_alpha\n",
    "from static_data import word_generalization\n",
    "\n",
    "\n",
    "# TODO : evt indikere hvilke navneord der starte med stort bogstav(egenavne), evt. lave et opslag for at undersøge ordklasse for det første ord i sætningen \n",
    "# TODO : test hvilke standarization funktioner giver bedre resultater \n",
    "\n",
    "arrs = [\n",
    "    to_lower, \n",
    "    split_dash, \n",
    "    split_included_specials, \n",
    "    replace_tournament(tournaments),\n",
    "    replace_countries(countries), \n",
    "    replace_weekday(weekdays), \n",
    "    replace_finals,\n",
    "    replace_nationality(nationalities),\n",
    "    replace_digits\n",
    "]\n",
    "\n",
    "s = standardize(arrs)\n",
    "\n",
    "words_train_vocab.extend(word_generalization)\n",
    "words_train_vocab.extend(non_alpha)\n",
    "\n",
    "# Model constants.\n",
    "max_features = 7000\n",
    "sequence_length = 60\n",
    "\n",
    "vectorized_layer = vectorize_layer(max_features, sequence_length, s)\n",
    "\n",
    "text_ds = vectorized_layer.adapt(words_train_vocab)\n",
    "vect_vocab = vectorized_layer.get_vocabulary()\n",
    "\n",
    "print(\"Total vocab/max_features : \",  len(vect_vocab))\n",
    "\n",
    "print (vect_layer_2_text(vectorized_layer([\"Tidligere Formel 1-kører vinder PL-guld ,Den tidligere Formel 1-kører Alex Zanardi kørte galt i 2001 og mistede begge sine ben. I dag vandt han guld ved PL i håndcykel.\"]), vect_vocab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in train_data[0:50]:\n",
    "#     print(\"Original \\n:\", t)\n",
    "#     print(\"Text from vectorized: \\n\", vect_layer_2_text(\n",
    "#         vectorized_layer([t]), vect_vocab\n",
    "#         ))\n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_vect = vectorized_layer(train_data)\n",
    "val_data_vect = vectorized_layer(val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.4):\n",
    "        super().__init__()\n",
    "        self.att = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [keras.layers.Dense(ff_dim, activation=\"relu\"), keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TokenAndPositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tf.keras.metrics.BinaryAccuracy(threshold=0.97)\n",
    "m.update_state([[1], [1], [0], [0]], [[0.98], [0.98], [0], [0]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import random as python_random\n",
    "\n",
    "def get_cnn_model():\n",
    "\n",
    "    embedding_dim = 24\n",
    "\n",
    "    # A integer input for vocab indices.\n",
    "    inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "    # Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "    # 'embedding_dim'.\n",
    "    x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Conv1D + global max pooling\n",
    "    # x = layers.Conv1D(32, 11, padding=\"valid\", activation=\"relu\")(x)\n",
    "    # x = layers.Conv1D(128, 9, padding=\"valid\", activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Conv1D + global max pooling\n",
    "    x = layers.Conv1D(32, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    # x = layers.Conv1D(32, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "\n",
    "\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # We add a vanilla hidden layer:\n",
    "    # x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "    # We add a vanilla hidden layer:\n",
    "    # x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "    \n",
    "    cnn_model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "    # Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "    cnn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return cnn_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "import random as python_random\n",
    "\n",
    "\n",
    "def get_transformer_model():\n",
    "\n",
    "    embed_dim =  192 # Embedding size for each token\n",
    "    num_heads = 2  # Number of attention heads\n",
    "    ff_dim = 192  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "\n",
    "    # A integer input for vocab indices.\n",
    "    inputs = tf.keras.Input(shape=(sequence_length,), dtype=\"int64\")\n",
    "\n",
    "    # Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "    # 'embedding_dim'.\n",
    "    # x = layers.Embedding(max_features, embed_dim)(inputs)\n",
    "\n",
    "    embedding_layer = TokenAndPositionEmbedding(sequence_length, max_features, embed_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "    # x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x = transformer_block(x)\n",
    "    # x = layers.Dropout(0.1)(x)\n",
    "\n",
    "    # x = transformer_block(x)\n",
    "\n",
    "\n",
    "\n",
    "    # Conv1D + global max pooling\n",
    "    # x = layers.Conv1D(128, 10, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    # x = layers.Conv1D(128, 10, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "\n",
    "\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # We add a vanilla hidden layer:\n",
    "    # x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "    # x = layers.Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "\n",
    "    transformer_model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "    # Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "    bn =   tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.97)\n",
    "    \n",
    "    \n",
    "    transformer_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "    return transformer_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_model(name):\n",
    "    if (name == \"cnn\"):\n",
    "       return get_cnn_model()\n",
    "    elif (name == \"transformer\"):\n",
    "       return get_transformer_model()\n",
    "  \n",
    "\n",
    "def filter_max_accuracy(history, threshold = 0.95):\n",
    "    acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    list = []\n",
    "    for x in range(len(acc)):\n",
    "        if (acc[x] > threshold):\n",
    "            list.append(val_acc[x])\n",
    "\n",
    "    return np.array(list)\n",
    "\n",
    "models = [\"cnn\", \"transformer\"]\n",
    "\n",
    "callback_3_loss = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4)\n",
    "\n",
    "\n",
    "def mean_model_accuracy(mode_names, iterations, epochs = 20):\n",
    "\n",
    "  \n",
    "    results = []\n",
    "\n",
    "    for name in range(len(mode_names)):\n",
    "        model_name = mode_names[name]\n",
    "        val_accuracies = []\n",
    "        \n",
    "        for x in range(iterations):\n",
    "            model = prepare_model(model_name)\n",
    "\n",
    "            # Fit the model using the train and test datasets.\n",
    "            history = model.fit(train_data_vect, train_labels, epochs=epochs, batch_size=6, validation_data=(val_data_vect, val_labels), callbacks=[callback_3_loss])\n",
    "\n",
    "            max_val_acc = filter_max_accuracy(history)\n",
    "            val_accuracies.append(max(max_val_acc))\n",
    "            print(max(max_val_acc))\n",
    "            print(val_accuracies)\n",
    "        \n",
    "        d = dict(name = model_name, results = np.mean(np.squeeze(np.array(val_accuracies))))\n",
    "        results.append(d)\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_results = mean_model_accuracy(models, 8)\n",
    "# mean_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_format_round(result):\n",
    "    return round(result)\n",
    "\n",
    "def result_format_none(result):\n",
    "    return result\n",
    "\n",
    "def print_model_score(model):\n",
    "    score = model.evaluate(val_data_vect, val_labels, verbose=0)\n",
    "    print(\"Validation loss:\", score[0])\n",
    "    print(\"Validations accuracy:\", score[1])\n",
    "\n",
    "def print_validation_results(predictions, val_data, labels, formatter, only_incorrect = False):\n",
    "    print(\"Number of predictions\", len(predictions))\n",
    "    n_correct = 0\n",
    "    for x in range(len(val_data)):\n",
    "        correct_prediction = result_format_round(labels[x]) == result_format_round(predictions[x][0])\n",
    "        if correct_prediction:\n",
    "            n_correct += 1\n",
    "\n",
    "        if correct_prediction == False and labels[x] == 0:\n",
    "            print(\"VALIDATION SAMPLE TEXT: \\n\" ,val_data[x])\n",
    "            print(\"VALIDATION SAMPLE DE-VECTORIZED: \\n\" ,vect_layer_2_text(val_data_vect[x], vect_vocab))\n",
    "            print(\"LABEL -- :\" , labels[x])\n",
    "            print(\"PREDICTION -- :\" , formatter(predictions[x][0]), \" ---- float: \", predictions[x][0])\n",
    "            print(\"CORRECT PREDICTION: \", correct_prediction)\n",
    "            print(\"\\n\")\n",
    "\n",
    "    print(\"Number correct: \", n_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "139/139 [==============================] - 3s 15ms/step - loss: 1.3406e-04 - accuracy: 0.7133 - val_loss: 0.3565 - val_accuracy: 0.8444\n",
      "Epoch 2/6\n",
      "139/139 [==============================] - 2s 14ms/step - loss: 6.5180e-05 - accuracy: 0.8923 - val_loss: 0.2412 - val_accuracy: 0.8847\n",
      "Epoch 3/6\n",
      "139/139 [==============================] - 2s 14ms/step - loss: 3.5861e-05 - accuracy: 0.9471 - val_loss: 0.2412 - val_accuracy: 0.9078\n",
      "Epoch 4/6\n",
      "139/139 [==============================] - 2s 14ms/step - loss: 1.7398e-05 - accuracy: 0.9827 - val_loss: 0.2432 - val_accuracy: 0.9078\n",
      "Epoch 5/6\n",
      "139/139 [==============================] - 2s 14ms/step - loss: 9.1051e-06 - accuracy: 0.9940 - val_loss: 0.2584 - val_accuracy: 0.8963\n",
      "Epoch 6/6\n",
      "139/139 [==============================] - 2s 14ms/step - loss: 5.4007e-06 - accuracy: 0.9975 - val_loss: 0.2658 - val_accuracy: 0.9193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs= 6\n",
    "transformer_model = get_transformer_model()\n",
    "\n",
    "transformer_history = transformer_model.fit(train_data_vect, train_labels, epochs=epochs, batch_size=60, validation_data=(val_data_vect, val_labels),  class_weight=class_weight,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        [(None, 60)]              0         \n",
      "_________________________________________________________________\n",
      "token_and_position_embedding (None, 60, 192)           1355520   \n",
      "_________________________________________________________________\n",
      "transformer_block_13 (Transf (None, 60, 192)           371136    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_21 (Glo (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 193       \n",
      "=================================================================\n",
      "Total params: 1,726,849\n",
      "Trainable params: 1,726,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "209/209 [==============================] - 2s 6ms/step - loss: 0.6433 - accuracy: 0.6287 - val_loss: 0.5054 - val_accuracy: 0.7608\n",
      "Epoch 2/7\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.3678 - accuracy: 0.8490 - val_loss: 0.2931 - val_accuracy: 0.8818\n",
      "Epoch 3/7\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.2388 - accuracy: 0.9060 - val_loss: 0.2443 - val_accuracy: 0.8934\n",
      "Epoch 4/7\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.1763 - accuracy: 0.9358 - val_loss: 0.2249 - val_accuracy: 0.9222\n",
      "Epoch 5/7\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.1418 - accuracy: 0.9474 - val_loss: 0.2207 - val_accuracy: 0.9308\n",
      "Epoch 6/7\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.1202 - accuracy: 0.9547 - val_loss: 0.2404 - val_accuracy: 0.9164\n",
      "Epoch 7/7\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.0947 - accuracy: 0.9664 - val_loss: 0.2394 - val_accuracy: 0.9251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs= 7\n",
    "cnn_model = get_cnn_model()\n",
    "\n",
    "transformer_history = cnn_model.fit(train_data_vect, train_labels, epochs=epochs, batch_size=40, validation_data=(val_data_vect, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_36 (Embedding)     (None, None, 24)          168000    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, None, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, None, 32)          5408      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_22 (Glo (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 173,441\n",
      "Trainable params: 173,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model):\n",
    "    np.set_printoptions(precision = 5, suppress = True)\n",
    "    predictions = model.predict(val_data_vect)\n",
    "    print_model_score(model)\n",
    "    print(\"\\n\")\n",
    "    print_validation_results(predictions, val_data, val_labels, result_format_round)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"--- TRANSFORMER ---\")\n",
    "# print_results(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CNN ---\n",
      "Validation loss: 0.2393985539674759\n",
      "Validations accuracy: 0.9250720739364624\n",
      "\n",
      "\n",
      "Number of predictions 347\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Tennis . Wozniacki blev forelagt utrolig bedrift og kunne ikke skjule smilet . Wozniacki bliver lidt stolt, når hun reflekterer over sin karriere\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['tennis' '.' '[UNK]' 'blev' '[UNK]' 'utrolig' 'bedrift' 'og' 'kunne'\n",
      " 'ikke' 'skjule' '[UNK]' '.' '[UNK]' 'bliver' 'lidt' 'stolt' 'når' 'hun'\n",
      " '[UNK]' 'over' 'sin' 'karriere']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.50520664\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Formel 1 . Magnussen øjner chancen for point . Kevin Magnussen hæfter sig ved, at banen i Singapore er svær at overhale på\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['formel' 'xnumber' '.' '[UNK]' 'øjner' 'chancen' 'for' 'point' '.'\n",
      " '[UNK]' '[UNK]' 'hæfter' 'sig' 'ved' 'at' 'banen' 'i' 'xland' 'er' 'svær'\n",
      " 'at' 'overhale' 'på']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.5282859\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Håndbold . Nyegaard begejstret efter Hansen-comeback . Mikkel Hansen spillede søndag sin første turneringskamp siden februar\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['håndbold' '.' '[UNK]' 'begejstret' 'efter' '[UNK]' 'comeback' '.'\n",
      " '[UNK]' '[UNK]' 'spillede' 'xweekday' 'sin' 'første' '[UNK]' 'siden'\n",
      " 'xweekday']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.9063624\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Kort sport . Stjernespiller trækker sig fra Paris Masters efter nattekamp . Verdens nummer fire Jannik Sinner har trukket sig fra den igangværende ATP Masters 1000-turnering i Paris\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['kort' 'sport' '.' 'stjernespiller' 'trækker' 'sig' 'fra' '[UNK]'\n",
      " 'xtournament' 'efter' '[UNK]' '.' 'verdens' 'nummer' 'fire' '[UNK]'\n",
      " '[UNK]' 'har' 'trukket' 'sig' 'fra' 'den' 'igangværende' 'xtournament'\n",
      " 'xtournament' 'xnumber' 'xtournament' 'i' '[UNK]']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.52751195\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Ishockey . Nykårede mestre slutter sig til VM-bruttotrup . Flere nationale mestre fra Danmark, Sverige og Østrig ? samt Nikolaj Ehlers ? er udtaget til VM-bruttotruppen\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['ishockey' '.' 'nykårede' 'mestre' 'slutter' 'sig' 'til' 'xtournament'\n",
      " 'bruttotrup' '.' 'flere' 'nationale' 'mestre' 'fra' 'xland' 'xland' 'og'\n",
      " '[UNK]' 'samt' '[UNK]' '[UNK]' 'er' 'udtaget' 'til' 'xtournament' '[UNK]']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.90774876\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " SPORT . Le Mans-legende er favorit til sejr . Kristensen var hurtigst, da deltagerne i det franske langdistanceløb mødtes til test\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['sport' '.' 'xtournament' 'legende' 'er' 'favorit' 'til' 'sejr' '.'\n",
      " '[UNK]' 'var' 'hurtigst' 'da' 'deltagerne' 'i' 'det' 'xnationality'\n",
      " '[UNK]' 'mødtes' 'til' 'test']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.9894438\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Fodbold . Elkjær hyldet for ikonisk mål . I Verona glemmer de ikke, at Preben Elkjær engang scorede et mål uden støvle på foden\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['fodbold' '.' '[UNK]' 'hyldet' 'for' 'ikonisk' 'mål' '.' 'i' '[UNK]'\n",
      " 'glemmer' 'de' 'ikke' 'at' '[UNK]' '[UNK]' 'engang' 'scorede' 'et' 'mål'\n",
      " 'uden' '[UNK]' 'på' 'foden']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.9982381\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Fodbold . - Jeg har aldrig prøvet noget lignende, siger dansk matchvinder . 22-årige Matt O'Riley blev nærmest overfaldet af lykkelige Celtic-fans\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['fodbold' '.' 'jeg' 'har' 'aldrig' 'prøvet' 'noget' 'lignende' 'siger'\n",
      " 'xnationality' 'matchvinder' '.' 'xnumber' 'årige' '[UNK]' '[UNK]'\n",
      " '[UNK]' 'blev' 'nærmest' '[UNK]' 'af' 'lykkelige' '[UNK]' 'fans']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.5615686\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " EM HÅNDBOLD . Selvom Danmark ikke har tryllet sig i EM-finalen, kan det godt blive en magisk aften . Danmark kan søndag vinde EM-guld ved at slå Norge i finalen. Det ville i så fald være håndboldkvindernes første titel siden 2004\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['xtournament' 'håndbold' '.' 'selvom' 'xland' 'ikke' 'har' '[UNK]' 'sig'\n",
      " 'i' 'xtournament' 'xfinalen' 'kan' 'det' 'godt' 'blive' 'en' 'magisk'\n",
      " 'aften' '.' 'xland' 'kan' 'xweekday' 'vinde' 'xtournament' 'guld' 'ved'\n",
      " 'at' 'slå' 'xland' 'i' 'xfinalen' '.' 'det' 'ville' 'i' 'så' 'fald'\n",
      " 'være' '[UNK]' 'første' 'titel' 'siden' 'xyear']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.8835718\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Baseball . Ny tilskuerrekord i Boston . Det amerikanske baseball-mandskab Boston Red Sox satte natten til tirsdag ny rekord, da holdet spillede sin udsolgte kamp nummer 456 på stribe hjemme på Fenway Park\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['baseball' '.' 'ny' 'tilskuerrekord' 'i' 'boston' '.' 'det'\n",
      " 'xnationality' 'baseball' 'mandskab' 'boston' 'red' '[UNK]' 'satte'\n",
      " 'natten' 'til' 'xweekday' 'ny' 'rekord' 'da' 'holdet' 'spillede' 'sin'\n",
      " 'udsolgte' 'kamp' 'nummer' 'xnumber' 'på' 'stribe' 'hjemme' 'på' '[UNK]'\n",
      " 'park']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.98890114\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Badminton . Det dufter af ren dansk VM-finale i Royal Arena, mener eksperter . De danske herresingler har endnu ikke afgivet et sæt\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['badminton' '.' 'det' '[UNK]' 'af' 'ren' 'xnationality' 'xtournament'\n",
      " 'xfinale' 'i' 'royal' 'arena' 'mener' 'eksperter' '.' 'de' 'xnationality'\n",
      " '[UNK]' 'har' 'endnu' 'ikke' '[UNK]' 'et' 'sæt']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.527907\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "VALIDATION SAMPLE TEXT: \n",
      " Vinter-OL . DIF udtager grønlandsk skiskytte til vinter-OL . Ukaleq Slettemark er atlet nummer 62 på det danske OL-holdkort. Hun stiller op i skiskydning ved vinter-OL\n",
      "VALIDATION SAMPLE DE-VECTORIZED: \n",
      " ['vinter' 'xtournament' '.' '[UNK]' 'udtager' 'xnationality' 'skiskytte'\n",
      " 'til' 'vinter' 'xtournament' '.' '[UNK]' '[UNK]' 'er' 'atlet' 'nummer'\n",
      " 'xnumber' 'på' 'det' 'xnationality' 'xtournament' '[UNK]' '.' 'hun'\n",
      " 'stiller' 'op' 'i' 'skiskydning' 'ved' 'vinter' 'xtournament']\n",
      "LABEL -- : 0\n",
      "PREDICTION -- : 1  ---- float:  0.6626832\n",
      "CORRECT PREDICTION:  False\n",
      "\n",
      "\n",
      "Number correct:  321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- CNN ---\")\n",
    "print_results(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00669, -0.02159,  0.04183, ...,  0.00198, -0.0006 , -0.01905],\n",
       "       [ 0.04439, -0.07039,  0.05189, ...,  0.05289, -0.01606, -0.02885],\n",
       "       [ 0.01797,  0.02886, -0.0312 , ...,  0.05552,  0.01674,  0.00579],\n",
       "       ...,\n",
       "       [ 0.03374,  0.03985, -0.01472, ..., -0.02742,  0.04566,  0.00264],\n",
       "       [-0.00068,  0.04357,  0.01216, ..., -0.01043, -0.00152,  0.02768],\n",
       "       [-0.0201 ,  0.03881,  0.03701, ..., -0.00395,  0.01419, -0.0477 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set up a logs directory, so Tensorboard knows where to look for files.\n",
    "\n",
    "ll = transformer_model.layers[1]\n",
    "ll_weights = ll.get_weights()[0]\n",
    "\n",
    "# print(ll_weights.shape)\n",
    "ll_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import I/O module in python\n",
    "import io\n",
    "\n",
    "##open the text stream for vectors\n",
    "vectors = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "##open the text stream for metadata\n",
    "meta = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "\n",
    "##write each word and its corresponding embedding\n",
    "for index in range(1, len(vect_vocab)):\n",
    "  word = vect_vocab[index]  # flipping the key-value in word_index\n",
    "  embeddings = ll_weights[index]\n",
    "  meta.write(word + \"\\n\")\n",
    "  vectors.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "\n",
    "##close the stream\n",
    "vectors.close()\n",
    "meta.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import collocations\n",
    "# bigram_measures = collocations.BigramAssocMeasures()\n",
    "# finder = collocations.BigramCollocationFinder.from_words([\"New\", \"York\", \"is\", \"big\", \"New\", \"York\", \"is\", \"dirty\"])\n",
    "# finder.ngram_fd.items()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lemmy\n",
    "# # Create an instance of the standalone lemmatizer.\n",
    "# lemmatizer = lemmy.load(\"da\")\n",
    "\n",
    "# # Find lemma for the word 'akvariernes'. First argument is an empty POS tag.\n",
    "# lemmatizer.lemmatize(\"NOUN\", \"verdensetter\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk as nltk\n",
    "# # from string import punctuation\n",
    "# # from nltk.corpus import stopwords\n",
    "# # nltk.download('stopwords')\n",
    "\n",
    "# # da_stopwords = stopwords.words(\"danish\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A string input\n",
    "inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n",
    "# Turn strings into vocab indices\n",
    "indices = vectorized_layer(inputs)\n",
    "# Turn vocab indices into predictions\n",
    "outputs = cnn_model(indices)\n",
    "\n",
    "# Our end to end model\n",
    "end_to_end_model = tf.keras.Model(inputs, outputs)\n",
    "end_to_end_model.compile(\n",
    "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "[[0.94015]\n",
      " [0.99749]\n",
      " [0.99998]\n",
      " [0.99921]\n",
      " [0.76779]]\n",
      "\n",
      " NON-Results:\n",
      "[[0.50599]\n",
      " [0.01442]\n",
      " [0.08571]\n",
      " [0.78971]\n",
      " [0.04106]\n",
      " [0.00578]\n",
      " [0.00561]\n",
      " [0.3306 ]\n",
      " [0.98937]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResults:\")\n",
    "\n",
    "\n",
    "print(end_to_end_model.predict(\n",
    "    [\n",
    "      \"Fodbold . Fjerritslev vinder over Vordingborg. Træner kommenterer på historisk kamp\",\n",
    "       \"SPORT . Hun vandt bronze i mandags Roer Anne Dsane Andersen har som 24-årig vundet bronze ved OL\",\n",
    "       \"Badminton . Axelsen frustreret over nederlag. Viktor Axelsen trænger til ferie efter nedturen\",\n",
    "      \"OL . Det blev til en flot medalje til Malene dfhsds. 'Jeg er meget lykkelig for resultatet'\",\n",
    "      \"Badminton . Dansker er videre til finalerne. dsfsdf sfdsdf bankede Fdfsdf fra Kina og skal spille i finalen på onsdag\",\n",
    "     ]))\n",
    "\n",
    "\n",
    "print(\"\\n NON-Results:\") \n",
    "print(end_to_end_model.predict(\n",
    "    [\n",
    "      \"Badminton . Dansker er videre til finalerne. dsfsdf sfdsdf skal spille i finalen på onsdag\",\n",
    "      \"OL Meget skal ske før en medalje kommer inden for rækkevidde. Dressurrytter Malene dsds har mistet troen på success\",\n",
    "      \"Fodbold . Træner for Fjerritslev ser frem til sejr over Vordingborg. 'Det bliver en historisk kamp'\",\n",
    "      \"Fodbold . De danske spillere skal op imod Sverige, som de tabte til i 2022\",\n",
    "      \"Fodbold . De danske spillere vil forsøge at besejre Tyrkiet den kommende Lørdag i VM-kamp. Tyrkiet har aldriv været i en VM-finale\",\n",
    "      \"Fodbold . De danske spillere tror på sejr mod Tyrkiet. 'Den skal vindes'\",\n",
    "      \"Skisport . Sverige drømmer om flere medaljer og sejre til næste års OL . Træner forventer flere gode resultater\",\n",
    "      \"Boksning . Kesler vil overraske alle og gøre det umulige. 'Jeg vinder i VM'\",\n",
    "      \"Boksning . Kesler med stor selvtillid: 'Det bliver guld eller sølv til VM'\",\n",
    "    \n",
    "     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " IN-BETWEEN-Results:\n",
      "[[0.99742]\n",
      " [0.98407]\n",
      " [0.16115]\n",
      " [0.3797 ]\n",
      " [0.60097]\n",
      " [0.00492]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n IN-BETWEEN-Results:\") \n",
    "print(end_to_end_model.predict(\n",
    "    [\n",
    "       \"Fodbold . Fjerritslev vandt i lørdags over Vordingborg 1-0. Den danske anfører dasdad dasdasd triumferer\",\n",
    "       \"Fodbold . Fjerritslev vandt i lørdags over Vordingborg. Den danske anfører adasdasdd daddas triumferer\",\n",
    "       \"Fodbold . Fjerritslev vandt i lørdags over Vordingborg. Efter kampen meddelyte den danske anfører sdfd sdfdf, at han skal under kniven\",\n",
    "       \"Fodbold . Superliga-profil efter storsejr over Vordingborg. ' Den danske anfører fsdsdff sdffsd skal opereres og er ude i flere måneder\",\n",
    "       \"Fodbold . Superliga-profil har meddelelse efter sejr. Den danske anfører fdfd sdffdf skal opereres og er ude i flere måneder\",\n",
    "       \"Fodbold . Superliga-profil kan se frem til en længere pause. Den danske anfører fdfd sdfff skal opereres og er ude i flere måneder\",\n",
    "       \n",
    "        ]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be0503bf1d8a1ee3ca0077be831d95fbcddd9686f11808f41fa1809452b7e6ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('newenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
